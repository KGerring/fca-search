#!/Library/Frameworks/Python.framework/Versions/3.2/bin/python3

from retrieval.search_engine import SearchEngine
from other.data import getStopWords
from other.constants import DATABASES_FOLDER, DATA_FOLDER
from retrieval.index import Index
from fca_extension.fca_search_engine import FCASearchEngine
import getopt, sys
from common.io import readfile
from preprocess.index_manager import IndexManager
from other.stopwatch import Stopwatch
import json

## functions 
def printSearch(searchResults):
	results = searchResults['origin']
	documents = results['documents']
	
	if documents:
		maxURL = max(len(x['url']) for x in documents)
		if 'matweb' in documents[0]['url']:
			maxURL = maxURL - len('http://localhost/matweb/') + len('matweb.cz/')
		maxKeywords = max([len(repr(x['keywords'][:3])) for x in documents])
		maxPos = len(str(len(documents)))
		maxScore = max(len(str(round(x['score'], 3))) for x in documents) + 1
		
		print(''.ljust(maxPos), 'URL'.ljust(maxURL), 'KEYWORDS'.ljust(maxKeywords), 'SCORE'.ljust(maxScore), 'WORDSCOUNT')
		for pos, item in enumerate(documents):
			score = str(round(item['score'], 3))
			url = item['url'].replace('http://localhost/matweb/', 'matweb.cz/')
			keywords = repr(item['keywords'][:3])
			wordscount = item['words']
	
			print(str(pos+1).ljust(maxPos), url.ljust(maxURL), keywords.ljust(maxKeywords), score.ljust(maxScore), wordscount)
	
	gen, sib, spec = getFcaExt(searchResults)
	
	print()
	print('Generalization' + str(gen))
	print('Specialization:' + str(spec))
	print('Siblings:' + str(sib))
	print('Search query: ' + str(results['parsedQuery']))
	print('Number results: ' + str(len(documents)))
	print()
	
def printJson(searchResults):
	gen, sib, spec = getFcaExt(searchResults)
	
	results = searchResults['origin']
	documents = results['documents']
	fca = {'gen':gen, 'spec':spec, 'sib':sib}
	data = {'documents':documents, 'fca': fca}
	jsonData = json.dumps(data)
	print(jsonData)
	
def getFcaExt(searchResults):
	spec = searchResults['specialization']
	gen = searchResults['generalization']
	sib = searchResults['siblings']
	
	return gen, sib, spec

def search(databaseName, query, outFormat):
	database = DATABASES_FOLDER + databaseName + '/'
	index = Index(database)
	searchEngine = SearchEngine(index, getStopWords())
	fca = FCASearchEngine(searchEngine, index)
	searchResults = fca.search(query)
	if outFormat == 'console':
		printSearch(searchResults)
	elif outFormat == 'json':
		printJson(searchResults)
	
def buildIndex(databaseName, linksSourcePath, maxLinksToDownload):
	database = DATABASES_FOLDER + databaseName + '/'
	links = readfile(linksSourcePath).splitlines()
	if maxLinksToDownload:
		links = links[:int(maxLinksToDownload)]
	indexManager = IndexManager()
	indexManager.shutUp = False
	indexManager.build(links, database, getStopWords())
	
def rebuildIndex(databaseName, newLinks = []):
	database = DATABASES_FOLDER + databaseName + '/'
	indexManager = IndexManager()
	indexManager.shutUp = False
	indexManager.rebuild(newLinks, database, getStopWords())
	
	
## main

if __name__ == '__main__':
	stopwatch = Stopwatch().start()
	
	try:
		opts, args = getopt.getopt(sys.argv[1:], 'd:q:b:p:f:m:r:a:')
		opts = dict(opts)
		
		# search in database
		if '-q' in opts:
			outFormat = opts.get('-f', 'console')
			search(opts['-d'], opts['-q'], outFormat)
			if outFormat == 'console':
				stopwatch.elapsed('Done')
				print(stopwatch)
				
		# build index
		elif '-b' in opts:
			databaseName = opts['-b']
			linksSourcePath = opts.get('-p', DATA_FOLDER + opts['-b'] + '.txt')
			maxLinksToDownload = int(opts.get('-m', 0))
			buildIndex(databaseName, linksSourcePath, maxLinksToDownload)
		
		# refresh index
		elif '-r' in opts:
			rebuildIndex(opts['-r'])
			
		# add links to index
		elif '-a' in opts:
			databaseName = opts['-a']
			linksSourcePath = opts.get('-p')
			links = readfile(linksSourcePath).splitlines()
			print(links)
			rebuildIndex(databaseName, links)
	except getopt.GetoptError as err:
		print(err) 
		sys.exit(2)